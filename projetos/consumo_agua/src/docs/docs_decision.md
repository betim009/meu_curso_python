# Documenta√ß√£o T√©cnica - Modelos de Previs√£o (Decision)

Este documento explica detalhadamente as fun√ß√µes implementadas no arquivo `decision.py`, assim como os conceitos estat√≠sticos e de aprendizado de m√°quina utilizados para prever o consumo de √°gua a partir das vari√°veis `Classe` e `Regi√£o`.

---

## 1. Objetivo
A an√°lise descritiva (m√©dia, mediana, moda, dispers√£o) mostra como os dados se comportam **no presente**.  
J√° os modelos de previs√£o t√™m como objetivo **estimar o consumo futuro** ou prever valores desconhecidos, ajudando no planejamento e tomada de decis√£o.

---

## 2. Fun√ß√µes implementadas

### `train_linear()`
- Modelo: **Regress√£o Linear**.
- L√≥gica: assume que h√° uma rela√ß√£o **linear** entre as vari√°veis `Classe`, `Regi√£o` e o `Consumo`.
- Uso: r√°pido e interpret√°vel, mas limitado se os dados n√£o seguem uma tend√™ncia linear.

---

### `train_decision_tree()`
- Modelo: **√Årvore de Decis√£o**.
- L√≥gica: divide os dados em **regras hier√°rquicas**, criando ramos baseados em condi√ß√µes (ex.: "Se Regi√£o = Sul, v√° para a esquerda; se Classe = Comercial, v√° para a direita").
- Uso: capta rela√ß√µes **n√£o lineares**. Melhor que a regress√£o linear em muitos casos, mas pode sofrer de *overfitting* (memorizar os dados).

---

### `train_random_forest()`
- Modelo: **Random Forest**.
- L√≥gica: constr√≥i **v√°rias √°rvores de decis√£o** e combina os resultados (m√©dia das previs√µes).
- Uso: mais robusto que uma √°rvore simples, reduz risco de *overfitting*, normalmente atinge melhor performance.

---

### `compare_models()`
- Executa os tr√™s modelos (Linear, Decision Tree e Random Forest).
- Imprime os resultados de **MSE** e **R¬≤** para facilitar a compara√ß√£o.
- √ötil para escolher qual modelo se adapta melhor aos dados.

---

## 3. M√©tricas de avalia√ß√£o

### üîπ MSE (Mean Squared Error ‚Äì Erro Quadr√°tico M√©dio)
- Mede o erro m√©dio entre valores previstos e reais.
- F√≥rmula:

\[
MSE = \frac{1}{n} \sum (y_i - \hat{y}_i)^2
\]

- Quanto **menor**, melhor.  
- Como os erros s√£o elevados ao quadrado, valores muito distantes pesam mais.

---

### üîπ R¬≤ (Coeficiente de Determina√ß√£o)
- Mede **quanto da varia√ß√£o nos dados o modelo consegue explicar**.
- F√≥rmula:

\[
R^2 = 1 - \frac{\text{Soma dos erros do modelo}}{\text{Soma dos erros da m√©dia}}
\]

- Intervalo: de -‚àû at√© 1.
  - 0 ‚Üí modelo n√£o explica nada.
  - 1 ‚Üí previs√£o perfeita.
- Exemplo: `R¬≤ = 0.63` significa que **63% da varia√ß√£o do consumo** √© explicada pelo modelo.

---

## 4. Interpreta√ß√£o dos resultados

- **Regress√£o Linear**  
  MSE alto, R¬≤ baixo (~0.45). Captura pouco da varia√ß√£o, porque os dados n√£o seguem um padr√£o linear simples.

- **√Årvore de Decis√£o**  
  MSE menor, R¬≤ melhor (~0.62). Captura padr√µes mais complexos, mas pode sobreajustar.

- **Random Forest**  
  Melhor desempenho at√© agora (R¬≤ ~0.63). Mais est√°vel, combina v√°rias √°rvores, reduzindo erros.

---

## 5. Por que usar modelos de previs√£o?

- Entender **tend√™ncias futuras de consumo**.
- **Planejar recursos** (infraestrutura, abastecimento).
- **Comparar cen√°rios** (ex.: impacto de mudan√ßas na Classe ou Regi√£o).
- **Descobrir vari√°veis mais relevantes** para o consumo.

---

## 6. Explica√ß√£o detalhada do c√≥digo

Nesta se√ß√£o, explicamos linha por linha do arquivo `decision.py`, detalhando cada m√©todo, fun√ß√£o e par√¢metro utilizado.

---

### Importa√ß√µes de bibliotecas

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
```

- `pandas` ‚Üí manipula√ß√£o de dados em DataFrames.
- `train_test_split` ‚Üí divide os dados em conjunto de treino e teste.
- `LinearRegression` ‚Üí modelo de regress√£o linear.
- `DecisionTreeRegressor` ‚Üí modelo baseado em √°rvore de decis√£o para regress√£o.
- `RandomForestRegressor` ‚Üí modelo de floresta aleat√≥ria para regress√£o.
- `mean_squared_error` ‚Üí calcula o MSE (erro quadr√°tico m√©dio).
- `r2_score` ‚Üí calcula o R¬≤ (coeficiente de determina√ß√£o).

---

### Estrutura geral das fun√ß√µes

Cada fun√ß√£o segue a mesma l√≥gica:
1. Carregar os dados (`pd.read_csv`).
2. Transformar vari√°veis categ√≥ricas (`pd.get_dummies`).
3. Definir vari√°veis explicativas (X) e vari√°vel alvo (y).
4. Dividir os dados em treino e teste (`train_test_split`).
5. Criar e treinar o modelo (`fit`).
6. Fazer previs√µes (`predict`).
7. Avaliar desempenho com m√©tricas (MSE e R¬≤).

---

### `train_linear()`

```python
df = pd.read_csv("./data/file_0.csv")
```
- L√™ os dados do arquivo CSV.

```python
X = pd.get_dummies(df[["Classe", "Regiao"]], drop_first=True)
y = df["Consumo"]
```
- `X`: vari√°veis independentes (Classe e Regi√£o), transformadas em num√©ricas com `get_dummies` (One-Hot Encoding).  
- `drop_first=True`: evita multicolinearidade removendo uma categoria de refer√™ncia.  
- `y`: vari√°vel dependente (Consumo).

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
- Divide os dados em treino (80%) e teste (20%).  
- `test_size=0.2`: define a propor√ß√£o.  
- `random_state=42`: garante reprodutibilidade (sempre a mesma divis√£o).

```python
model = LinearRegression()
model.fit(X_train, y_train)
```
- Cria o modelo de regress√£o linear e treina com os dados de treino.  
- `fit`: ajusta os coeficientes do modelo.

```python
y_pred = model.predict(X_test)
```
- Faz previs√µes no conjunto de teste.

```python
print("MSE:", mean_squared_error(y_test, y_pred))
print("R¬≤:", r2_score(y_test, y_pred))
```
- Calcula e exibe as m√©tricas de avalia√ß√£o.

---

### `train_decision_tree()`

```python
model = DecisionTreeRegressor(max_depth=5, random_state=42)
```
- Cria uma √°rvore de decis√£o com profundidade m√°xima = 5.  
- `max_depth`: limita a complexidade da √°rvore (evita overfitting).  
- `random_state=42`: garante consist√™ncia nos resultados.

---

### `train_random_forest()`

```python
model = RandomForestRegressor(n_estimators=100, random_state=42)
```
- Cria uma floresta com 100 √°rvores.  
- `n_estimators=100`: n√∫mero de √°rvores usadas na m√©dia das previs√µes.  
- `random_state=42`: garante reprodutibilidade.

---

### `compare_models()`

```python
models = {
    "Regress√£o Linear": LinearRegression(),
    "√Årvore de Decis√£o": DecisionTreeRegressor(max_depth=5, random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
}
```
- Define um dicion√°rio com tr√™s modelos para compara√ß√£o.  
- Itera sobre eles, treinando e testando cada um.  
- Exibe MSE e R¬≤ para facilitar a an√°lise.

---

## Conclus√£o

O arquivo `decision.py` mostra tr√™s abordagens diferentes de previs√£o: linear, √°rvore de decis√£o e random forest. Cada modelo tem vantagens e limita√ß√µes, e a escolha depende do equil√≠brio entre **interpreta√ß√£o**, **performance** e **complexidade**.
